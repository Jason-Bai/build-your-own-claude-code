# 项目测试方案总结 (Testing Plan Summary)

## 📊 一眼看清项目测试现状和方向

### 现状分析

| 指标 | 数值 |
|------|------|
| 源代码文件 | 48 个 |
| 总代码行数 | 6,600+ 行 |
| 当前测试文件 | 2 个 |
| 当前测试用例 | ~40 个 |
| 当前覆盖率 | ~5% (仅 hooks 模块) |
| **覆盖差距** | **95%** |

### 为什么需要完善测试？

**项目要存活下去，需要：**

1. **质量保证** - 用户信任
   - 80%+ 覆盖率 → "这个项目的代码质量不错"
   - 100% 通过率 → "这个项目可靠"
   - CI/CD 集成 → "这个项目在维护中"

2. **降低维护成本** - 开发者效率
   - 新功能有测试保护 → 可以安心重构
   - 回归测试自动化 → 不怕改出 bug
   - 代码改动可追溯 → 快速定位问题

3. **吸引贡献者** - 社区生态
   - 测试齐全 → PR 审查更快
   - 覆盖率透明 → 知道要补什么
   - 贡献门槛低 → 新人可以参与

---

## 🎯 测试方案要点

### 模块分级 & 优先级

```
P0 (核心功能, 85% 覆盖率):
├── agents/ (1,171 行)        - Agent 状态机、工具管理
├── clients/ (770 行)          - LLM 多提供商支持
└── tools/ (871 行)            - 文件、命令、搜索工具

P1 (重要功能, 80% 覆盖率):
├── hooks/ (1,122 行)          - Hook 系统 (已有 40 测试)
├── events/ (193 行)           - 事件总线
└── commands/ (725 行)         - CLI 命令系统

P2 (辅助功能, 65-70% 覆盖率):
├── utils/ (593 行)            - 输入/输出增强
├── mcps/ (153 行)             - MCP 集成
└── prompts/ (306 行)          - 提示词管理
```

### 测试数量分配

```
目标: 140+ 测试用例

P0 模块:
├── 单元测试: 100 个
└── 集成测试: 26 个

P1 模块:
├── 单元测试: 45 个
└── 集成测试: 20 个

P2 模块:
├── 单元测试: 30 个
└── E2E 测试: 10 个
```

### 模块详解

#### 🤖 Agent System (35-40 + 8-12 tests)

**核心价值：** Agent 是整个系统的大脑

**测试内容：**
- FSM 状态转换 (IDLE → THINKING → USING_TOOL → COMPLETED)
- Token 计数准确性
- 上下文压缩触发 (80% 时自动压缩)
- 工具重试逻辑 (指数退避)
- 错误隔离 (一个工具失败不影响整体)
- 权限系统 (SAFE/NORMAL/DANGEROUS)

**为什么重要：** Agent 工作不正常，整个项目就废了

#### 🤖 LLM Clients (25-30 + 6-8 tests)

**核心价值：** 支持多个 LLM 提供商

**测试内容：**
- Anthropic/OpenAI/Google 都能正常工作
- API 请求格式正确
- 错误处理 & 重试
- Token 估算准确
- 供应商切换

**为什么重要：** 用户可能用不同 LLM，需要都支持

#### 🔧 Tool System (40-45 + 10-12 tests)

**核心价值：** 工具是 Agent 的执行手段

**测试内容：**
- 文件读写编辑
- Bash 命令执行
- 搜索 (Glob/Grep)
- 待办事项管理
- 超时处理
- 权限检查

**为什么重要：** 工具执行出错，用户体验就差

#### 🪝 Hook System (Already 40, need +15-20)

**核心价值：** 用户可以扩展功能

**额外测试：**
- Hook 代码安全加载 (沙箱)
- 配置文件加载
- 优先级排序
- 错误隔离

**为什么重要：** Hook 是项目可扩展性的基础

---

## 📈 测试组织架构

### 文件结构

```
tests/
├── conftest.py                # Pytest 配置 + 共享 Fixtures
├── pytest.ini                 # Pytest 参数
├── unit/                      # 单元测试 (~95 个)
│   ├── test_agent_*.py
│   ├── test_clients_*.py
│   ├── test_tools_*.py
│   ├── test_commands.py
│   ├── test_events.py
│   └── ...
├── integration/               # 集成测试 (~40 个)
│   ├── test_agent_workflow.py
│   ├── test_tool_execution.py
│   ├── test_command_flow.py
│   └── ...
└── e2e/                       # 端到端测试 (~10 个)
    ├── test_complete_conversation.py
    └── ...
```

### 测试命令

```bash
# 运行所有测试
pytest tests/

# 查看覆盖率报告
pytest --cov=src --cov-report=html tests/

# 只运行单元测试
pytest tests/unit/

# 只运行集成测试
pytest tests/integration/

# 运行特定模块
pytest tests/unit/test_agent_state.py

# 详细输出
pytest -v tests/

# 失败时停止
pytest -x tests/
```

---

## 📋 实施时间表 (4 周计划)

### 第1周：基础设施
- [ ] 配置 conftest.py + pytest.ini
- [ ] 创建 shared fixtures
- [ ] 写 ~40 个 Agent 单元测试

### 第2周：继续单元测试
- [ ] ~30 个 Clients 测试
- [ ] ~45 个 Tools 测试
- [ ] ~20 个 Events 测试

### 第3周：集成测试 + Commands
- [ ] ~20 个 Hooks 集成测试
- [ ] ~25 个 Commands 测试
- [ ] ~15 个 Utils 测试

### 第4周：E2E + 完善
- [ ] ~10 个 E2E 测试
- [ ] 填补覆盖率空隙
- [ ] 设置 CI/CD

---

## 🎖️ 成功指标

| 指标 | 目标 | 用途 |
|------|------|------|
| 总测试数 | 140+ | 覆盖所有代码路径 |
| 覆盖率 | 80%+ | 用户信任 |
| P0 覆盖率 | 85%+ | 核心功能可靠 |
| 执行时间 | <60s | 开发者反馈快 |
| 通过率 | 100% | 零已知 bug |
| CI/CD | ✅ | 自动检测回归 |

---

## 💡 为什么这个方案能保证项目生存

### 对用户：
- "这个项目有 80% 的测试覆盖率" → 我放心用
- "所有测试都通过了" → 看起来很稳定
- "每次提交都自动运行测试" → 项目在积极维护

### 对贡献者：
- "有完整的测试框架" → 我知道怎么写测试
- "测试失败时 CI 会通知" → 我能快速发现问题
- "代码覆盖率透明" → 我知道还需要补什么

### 对项目本身：
- 防止回归（新改动不会破坏旧功能）
- 重构更安心（有测试保护）
- 快速定位问题（测试失败指向具体代码）
- 代码质量可量化（用覆盖率和通过率说话）

---

## 📚 详细文档

完整的测试计划请查看：**[docs/testing_strategy.md](./testing_strategy.md)**

包含：
- 每个模块的详细测试策略
- Mock 策略和 Fixtures 设计
- Pytest 配置详解
- GitHub Actions CI/CD 模板
- 预期覆盖率分解表

---

## 下一步行动

你想：

1. **立即启动实施** → 我帮你开始第1周的工作 (conftest.py + fixtures)
2. **先看代码示例** → 我给你展示几个测试用例的写法
3. **讨论调整** → 你觉得哪些模块优先级应该调整？

**你的想法？** 🚀
