#!/usr/bin/env python3
"""
è¿½è¸ªå®Œæ•´çš„æ¶ˆæ¯æµ - è°ƒè¯• Kimi å·¥å…·è°ƒç”¨é—®é¢˜
"""

import asyncio
import json
import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
load_dotenv()

from src.initialization.setup import initialize_agent
from src.config.loader import load_config


# çŒ´è¡¥ä¸ï¼šæ‹¦æˆª OpenAI å®¢æˆ·ç«¯çš„ create_message è°ƒç”¨
original_create_message = None

async def patched_create_message(self, system, messages, tools, max_tokens=8000, temperature=1.0, stream=False):
    """æ‹¦æˆªå¹¶è®°å½• create_message è°ƒç”¨"""
    print("\n" + "=" * 80)
    print("ğŸ” OpenAI å®¢æˆ·ç«¯æ”¶åˆ°çš„æ¶ˆæ¯:")
    print("=" * 80)

    print(f"\nğŸ“‹ ç³»ç»Ÿæç¤º: {system[:100]}...")
    print(f"\nğŸ“¬ æ¶ˆæ¯åˆ—è¡¨ (æ€»è®¡ {len(messages)} æ¡):")
    for i, msg in enumerate(messages):
        role = msg.get("role", "?")
        print(f"\n  {i}. role='{role}'")
        content = msg.get("content", [])
        if isinstance(content, list):
            print(f"     å†…å®¹å—æ•°: {len(content)}")
            for j, block in enumerate(content):
                block_type = block.get("type", "?")
                print(f"       [{j}] type='{block_type}'", end="")
                if block_type == "tool_result":
                    print(f" tool_call_id='{block.get('tool_call_id', 'MISSING')}'")
                elif block_type == "tool_use":
                    print(f" id='{block.get('id', 'MISSING')}'")
                else:
                    print()
        elif isinstance(content, str):
            print(f"     å†…å®¹: {content[:100]}...")

    print(f"\nğŸ”§ å·¥å…·å®šä¹‰æ•°: {len(tools)}")
    if tools:
        for tool in tools[:2]:
            print(f"   - {tool.get('name', '?')}")
        if len(tools) > 2:
            print(f"   ... è¿˜æœ‰ {len(tools) - 2} ä¸ªå·¥å…·")

    print("\n" + "=" * 80)
    print("ğŸ“¤ è½¬æ¢ä¸º OpenAI æ ¼å¼åçš„æ¶ˆæ¯:")
    print("=" * 80)

    # æ‰§è¡ŒåŸå§‹æ–¹æ³•
    result = await original_create_message(self, system, messages, tools, max_tokens, temperature, stream)

    # è®°å½• OpenAI API æ”¶åˆ°çš„æ¶ˆæ¯
    # ï¼ˆéœ€è¦é‡æ–°æ„é€ ï¼Œå› ä¸ºåŸå§‹æ–¹æ³•å·²æ‰§è¡Œï¼‰

    return result


async def test():
    """æµ‹è¯• Kimi å·¥å…·è°ƒç”¨ï¼Œè®°å½•æ¶ˆæ¯æµ"""

    print("=" * 80)
    print("å¼€å§‹è°ƒè¯• Kimi æ¶ˆæ¯æµ")
    print("=" * 80)

    from src.clients.openai import OpenAIClient
    global original_create_message
    original_create_message = OpenAIClient.create_message
    OpenAIClient.create_message = patched_create_message

    try:
        # åŠ è½½é…ç½®
        config = load_config()
        print(f"\nâœ… é€‰å®šæä¾›å•†: {config.get('model', {}).get('provider')}")

        # åˆå§‹åŒ– Agent
        class MockArgs:
            dangerously_skip_permissions = True
            auto_approve_all = False
            always_ask = False
            verbose = False

        agent = await initialize_agent(config, MockArgs())
        print(f"âœ… Agent åˆå§‹åŒ–æˆåŠŸï¼Œå®¢æˆ·ç«¯: {agent.client.__class__.__name__}")

        # è¿è¡Œä¸€ä¸ªç®€å•çš„è¯·æ±‚
        user_input = "list 3 python files"

        print(f"\nğŸ‘¤ ç”¨æˆ·è¾“å…¥: {user_input}")
        print(f"\nğŸ¤– Agent å¼€å§‹å¤„ç†...")

        result = await agent.run(user_input, verbose=False)

        print(f"\nâœ… Agent æ‰§è¡Œå®Œæˆ")
        print(f"å“åº”: {result.get('final_response', '')[:200]}...")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test())
