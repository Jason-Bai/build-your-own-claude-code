#!/usr/bin/env python3
"""
è¯¦ç»†è¿½è¸ªç¬¬äºŒè½® LLM è°ƒç”¨æ—¶çš„æ¶ˆæ¯çŠ¶æ€
"""

import asyncio
import json
import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
load_dotenv()

from src.initialization.setup import initialize_agent
from src.config.loader import load_config
from src.clients.openai import OpenAIClient

call_count = 0

original_create_message = OpenAIClient.create_message

async def patched_create_message(self, system, messages, tools, max_tokens=8000, temperature=1.0, stream=False):
    """æ‹¦æˆªå¹¶è¯¦ç»†è®°å½•ç¬¬äºŒè½®è°ƒç”¨"""
    global call_count
    call_count += 1

    print("\n" + "=" * 80)
    print(f"ğŸ” OpenAI.create_message è°ƒç”¨ #{call_count}")
    print("=" * 80)

    print(f"\nğŸ“¬ æ¥æ”¶åˆ°çš„æ¶ˆæ¯ (æ€»è®¡ {len(messages)} æ¡):")
    for i, msg in enumerate(messages):
        print(f"\n  [{i}] role={msg.get('role')}")
        content = msg.get("content", [])
        if isinstance(content, list):
            print(f"      contentå—æ•°={len(content)}")
            for j, block in enumerate(content):
                print(f"        [{j}] type={block.get('type')}", end="")
                if block.get("type") == "tool_use":
                    print(f" id='{block.get('id')}' name='{block.get('name')}'")
                elif block.get("type") == "tool_result":
                    tcid = block.get("tool_call_id") or block.get("tool_use_id")
                    print(f" tool_call_id='{tcid}'")
                else:
                    print()
        elif isinstance(content, str):
            print(f"      content='{content[:80]}...'")

    if call_count == 2:
        print("\nâš ï¸  è¿™æ˜¯ç¬¬äºŒè½®è°ƒç”¨ï¼è¯¦ç»†æ£€æŸ¥ assistant æ¶ˆæ¯ä¸­çš„ tool_use:")
        for i, msg in enumerate(messages):
            if msg.get("role") == "assistant" and isinstance(msg.get("content"), list):
                for block in msg.get("content", []):
                    if block.get("type") == "tool_use":
                        print(f"\nğŸ” æ‰¾åˆ° tool_use å—:")
                        print(f"   å®Œæ•´å†…å®¹: {json.dumps(block, indent=4, ensure_ascii=False)}")

    # è°ƒç”¨åŸå§‹
    return await original_create_message(self, system, messages, tools, max_tokens, temperature, stream)

OpenAIClient.create_message = patched_create_message


async def test():
    config = load_config()
    print(f"âœ… é€‰å®šæä¾›å•†: {config.get('model', {}).get('provider')}")

    class MockArgs:
        dangerously_skip_permissions = True
        auto_approve_all = False
        always_ask = False
        verbose = False

    agent = await initialize_agent(config, MockArgs())
    print(f"âœ… Agent åˆå§‹åŒ–æˆåŠŸ")

    user_input = "list 3 python files"
    print(f"\nğŸ‘¤ ç”¨æˆ·è¾“å…¥: {user_input}\n")

    try:
        result = await agent.run(user_input, verbose=False)
        print(f"\nâœ… æµ‹è¯•å®Œæˆ")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    asyncio.run(test())
